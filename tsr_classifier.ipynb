{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "# import pickle\n",
    "# import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(36)\n",
    "\n",
    "#list to store the training images into numpy array form \n",
    "train_img = []\n",
    "#list to store the class associated with the image\n",
    "train_img_class = []\n",
    "cwd = os.getcwd()\n",
    "#Retrieving the images and their labels \n",
    "for i in range(43):\n",
    "    img_root = os.path.join(cwd,'Train',str(i))\n",
    "    #path= D:\\codes\\ml_and_data_science\\cats_and_dog\\traffic\\train\\0\n",
    "    images = os.listdir(img_root)\n",
    "  \n",
    "    #running loop into each class of image\n",
    "    for j in images:\n",
    "      \n",
    "        actual_img = Image.open(img_root + '\\\\'+ j)\n",
    "        actual_img = actual_img.resize((30,30))\n",
    "        actual_img = np.array(actual_img)\n",
    "        train_img.append(actual_img)\n",
    "        train_img_class.append(i)\n",
    "       \n",
    "#Converting lists into numpy arrays\n",
    "train_img = np.array(train_img)\n",
    "train_img_class = np.array(train_img_class)\n",
    "print(train_img.shape, train_img_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
      "0     53      54       6       5      48      49       16  Test/00000.png\n",
      "1     42      45       5       5      36      40        1  Test/00001.png\n",
      "2     48      52       6       6      43      47       38  Test/00002.png\n",
      "3     27      29       5       5      22      24       33  Test/00003.png\n",
      "4     60      57       5       5      55      52       11  Test/00004.png\n",
      "(12630, 30, 30, 3) (12630,)\n"
     ]
    }
   ],
   "source": [
    "test_csv=pd.read_csv(\"Test.csv\")\n",
    "print(test_csv.head())\n",
    "test_img_path=test_csv.Path\n",
    "test_img_class=test_csv.ClassId\n",
    "\n",
    "test_img=[]\n",
    "test_class=[]\n",
    "# test_img_root=os.path.join(cwd+\"Train\")\n",
    "for i in range(len(test_img_path)):\n",
    "    actual_test_img=Image.open(cwd+'\\\\'+test_img_path[i])\n",
    "    actual_test_img = actual_test_img.resize((30,30))\n",
    "    actual_test_img = np.array(actual_test_img)\n",
    "        #sim = Image.fromarray(image)\n",
    "    test_img.append(actual_test_img)\n",
    "    test_class.append(test_img_class[i])\n",
    "       \n",
    "#Converting lists into numpy arrays\n",
    "test_img = np.array(test_img)\n",
    "test_class = np.array(test_class)\n",
    "print(test_img.shape, test_class.shape)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4dcdd72a6c87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_img_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#Building the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_class' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "train_img_class = to_categorical(train_img_class, 43)\n",
    "test_class = to_categorical(test_class, 43)\n",
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=train_img.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "epochs = 1\n",
    "history = model.fit(train_img, train_img_class, batch_size=32, epochs=epochs)\n",
    "#model.save(\"my_model3.h5\")\n",
    "#joblib.dump(model,'joblib_model.sav')\n",
    "#pickle.dump(model,open('pickle_model.sav','wb'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model.predict_classes(test_img)\n",
    "#Accuracy with the test data\n",
    "labels = test_csv[\"ClassId\"].values\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))\n",
    "#model.save(\"traffic_classifier2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test score:\",accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
